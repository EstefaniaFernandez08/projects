{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: #777777;\">Working Data Overview</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #777777;\">1. GNFR Invoice</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #777777;\">1.1. Data Overview</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GNFR I2P Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m dtype \u001b[39m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m     \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mINVOICE_LINE_AMOUNT\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     14\u001b[0m }\n\u001b[1;32m---> 16\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mGNFR I2P Data.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mUTF-8-SIG\u001b[39;49m\u001b[39m'\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m     18\u001b[0m df_shape \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mshape\n\u001b[0;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDataFrame shape:\u001b[39m\u001b[39m\"\u001b[39m, df_shape)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GNFR I2P Data.csv'"
     ]
    }
   ],
   "source": [
    "# Shape and Invoice amount per file\n",
    "import pandas as pd\n",
    "\n",
    "dtype = {\n",
    "\n",
    "    \n",
    "    'Source.Name': 'str',\n",
    "    'INVOICE_NBR': 'str',\n",
    "    'INVOICE_LINE_NBR': 'str',\n",
    "    'INVOICE_QTY': 'str',\n",
    "    'PO_NBR': 'str',\n",
    "    'SUPPLIER_NBR': 'str',\n",
    "}\n",
    "\n",
    "df = pd.read_csv('GNFR I2P Data.csv', encoding='UTF-8-SIG', dtype=dtype)\n",
    "\n",
    "df_shape = df.shape\n",
    "print(\"DataFrame shape:\", df_shape)\n",
    "\n",
    "# Calculate sum of INVOICE_LINE_AMOUNT for each Source.Name\n",
    "df_amount_sum = df.groupby('Source.Name')['INVOICE_LINE_AMOUNT'].sum()\n",
    "\n",
    "# Export df_amount_sum to a CSV file\n",
    "\n",
    "#df_amount_sum.to_csv('i2p_invoice_amount_sum.csv', header=True, encoding='UTF-8-SIG')\n",
    "\n",
    "\n",
    "print(\"\\nSum of INVOICE_LINE_AMOUNT for each Source.Name:\")\n",
    "print(df_amount_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for each Source.Name:\n",
      "Source.Name\n",
      "TBC_GNFRPO_01012022-01312022.CSV    19542\n",
      "TBC_GNFRPO_01012023-01312023.CSV    17789\n",
      "TBC_GNFRPO_02012022-02282022.CSV    17106\n",
      "TBC_GNFRPO_02012023-02282023.CSV    17378\n",
      "TBC_GNFRPO_03012022-03312022.CSV    19951\n",
      "TBC_GNFRPO_03012023-03312023.CSV    17774\n",
      "TBC_GNFRPO_05012021-05312021.CSV     5980\n",
      "TBC_GNFRPO_06012021-06302021.CSV     4639\n",
      "TBC_GNFRPO_06012022-06302022.CSV    20257\n",
      "TBC_GNFRPO_07012021-07312021.CSV     5765\n",
      "TBC_GNFRPO_07012022-07312022.CSV    17824\n",
      "TBC_GNFRPO_08012021-08312021.CSV     4234\n",
      "TBC_GNFRPO_09012021-09302021.CSV     6598\n",
      "TBC_GNFRPO_09012022-09302022.CSV    21022\n",
      "TBC_GNFRPO_10012021-10312021.CSV     5565\n",
      "TBC_GNFRPO_10012022-10312022.CSV    19568\n",
      "TBC_GNFRPO_11012021-11302021.CSV     6381\n",
      "TBC_GNFRPO_11012022-11302022.CSV    16221\n",
      "TBC_GNFRPO_12012021-12312021.CSV    15508\n",
      "TBC_GNFRPO_12012022-12312022.CSV    20429\n",
      "Name: Source.Name, dtype: int64\n",
      "Total Row count:\n",
      "279531\n"
     ]
    }
   ],
   "source": [
    "# Count rows for file\n",
    "df_row_count = df['Source.Name'].value_counts()\n",
    "\n",
    "# Sort df_row_count by the order of df_amount_sum's Source.Name column\n",
    "df_row_count = df_row_count.reindex(df_amount_sum.index)\n",
    "\n",
    "# Print row count for each Source.Name\n",
    "print(\"Row count for each Source.Name:\")\n",
    "print(df_row_count)\n",
    "\n",
    "df_row_count.to_csv('nonpo_row_count.csv', header=True, encoding='UTF-8-SIG')\n",
    "\n",
    "# Calculate total row count\n",
    "total_row_count = df_row_count.sum()\n",
    "print(\"Total Row count:\")\n",
    "print(total_row_count)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 323412 entries, 0 to 323411\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   INVOICE_DATE       323412 non-null  object \n",
      " 1   Source.Name        323412 non-null  object \n",
      " 2   INVOICE_LINE_NBR   323412 non-null  int64  \n",
      " 3   INVOICE_NBR        323412 non-null  object \n",
      " 4   ReferenceField     323412 non-null  object \n",
      " 5   INVOICE_PAID_DATE  323412 non-null  object \n",
      " 6   INVOICE_SOURCE     323412 non-null  object \n",
      " 7   INVOICE_TYPE       323412 non-null  object \n",
      " 8   INVOICE_QTY        0 non-null       float64\n",
      " 9   PO_NBR             323412 non-null  object \n",
      " 10  PO_ORDER_DATE      323412 non-null  object \n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 27.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#data types\n",
    "\n",
    "df.info(verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #777777;\">1.2. Transformation / Reports</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ReferenceField  Count of Distinct INVOICE_NBR\n",
      "32711                  2                             38\n",
      "8580                   1                             33\n",
      "101377      912-673-6184                             25\n",
      "97651   8535114591276833                             24\n",
      "6491           063132808                             24\n",
      "...                  ...                            ...\n",
      "49417       235084368001                              1\n",
      "49416       235070299001                              1\n",
      "49415       235066666001                              1\n",
      "49414       235064531001                              1\n",
      "146499           Z347150                              1\n",
      "\n",
      "[146500 rows x 2 columns]\n",
      "Count of ReferenceField with one count of Distinct INVOICE_NBR: 144487\n",
      "Count of ReferenceField with more than one count of Distinct INVOICE_NBR: 2013\n"
     ]
    }
   ],
   "source": [
    "#1. There are Multiple 'INVOICE_NBR' per 'ReferenceField': \n",
    "\n",
    "#groups the data by 'ReferenceField', calculates the count of distinct 'INVOICE_NBR' values within each group.\n",
    "\n",
    "ref_result = df.groupby('ReferenceField')['INVOICE_NBR'].nunique().reset_index()\n",
    "ref_result = ref_result.rename(columns={'INVOICE_NBR': 'Count of Distinct INVOICE_NBR'})\n",
    "ref_result = ref_result.sort_values(by='Count of Distinct INVOICE_NBR', ascending=False)\n",
    "\n",
    "print(ref_result)\n",
    "\n",
    "#ref_result.to_csv('Multiple_INVOICE_NBR_per_ReferenceField.csv', encoding='UTF-8-SIG')\n",
    "\n",
    "# Count of ReferenceField with one count of Distinct INVOICE_NBR\n",
    "one_count = ref_result[ref_result['Count of Distinct INVOICE_NBR'] == 1]['ReferenceField'].count()\n",
    "print(\"Count of ReferenceField with one count of Distinct INVOICE_NBR:\", one_count)\n",
    "\n",
    "# Count of ReferenceField with more than one count of Distinct INVOICE_NBR\n",
    "multiple_count = ref_result[ref_result['Count of Distinct INVOICE_NBR'] > 1]['ReferenceField'].count()\n",
    "print(\"Count of ReferenceField with more than one count of Distinct INVOICE_NBR:\", multiple_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of distinct exported reference fields: 2013\n",
      "DataFrame shape: (8430, 12)\n"
     ]
    }
   ],
   "source": [
    "# Table export gnfr Reference Field Inconsistencies\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Get the list of ReferenceField values that have more than one distinct INVOICE_NBR\n",
    "multiple_invoice_ref_fields = result[result['Count of Distinct INVOICE_NBR'] > 1]['ReferenceField']\n",
    "\n",
    "# Filter the original dataframe with this list\n",
    "df_multiple_invoice = df[df['ReferenceField'].isin(multiple_invoice_ref_fields)]\n",
    "\n",
    "# Check the count of distinct ReferenceField in the filtered dataframe\n",
    "print(\"Total of distinct exported reference fields:\", df_multiple_invoice['ReferenceField'].nunique())\n",
    "\n",
    "dtype = {\n",
    "    \n",
    "'Source.Name': 'str',\n",
    "'ACCOUNT_CDE': 'str',\n",
    "'INVOICE_NBR': 'str',\n",
    "'INVOICE_LINE_NBR': 'str',\n",
    "'SUPPLIER_NBR': 'str',\n",
    "'INVOICE_LINE_AMOUNT': 'float',\n",
    "}\n",
    "\n",
    "df_multiple_invoice = df_multiple_invoice.astype(dtype)\n",
    "df_multiple_invoice.replace('', np.nan, inplace=True)\n",
    "df_multiple_invoice.to_csv('gnfr_multiple_invoice_records.csv', index=False, encoding='UTF-8-SIG')\n",
    "\n",
    "df_shape = df_multiple_invoice.shape\n",
    "print(\"DataFrame shape:\", df_shape)\n",
    "\n",
    "\n",
    "#df_multiple_invoice.to_csv('gnfr_multiple_invoice_records.csv', index=False, encoding='UTF-8-SIG')\n",
    "df_multiple_invoice.to_csv('C:\\\\Users\\\\LOGICSOUERCE02\\\\Desktop\\\\gnfr_multiple_invoice_records.csv', index=False, encoding='UTF-8-SIG',na_rep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of reference fields present in 'result' but not in 'df_multiple_invoice': 0\n",
      "Total of distinct exported reference fields after de-duplication: 2013\n"
     ]
    }
   ],
   "source": [
    "#Test to make sure the multiple invoices are being exported correctly\n",
    "\n",
    "# Convert the series to sets\n",
    "set_multiple_invoice_ref_fields = set(multiple_invoice_ref_fields)\n",
    "set_df_multiple_invoice = set(df_multiple_invoice['ReferenceField'].unique())\n",
    "\n",
    "# Get the difference\n",
    "diff_ref_fields = set_multiple_invoice_ref_fields - set_df_multiple_invoice\n",
    "\n",
    "# Print the count of reference fields present in 'result' but not in 'df_multiple_invoice'\n",
    "print(\"Count of reference fields present in 'result' but not in 'df_multiple_invoice':\", len(diff_ref_fields))\n",
    "\n",
    "df_multiple_invoice_dedup = df_multiple_invoice.drop_duplicates(subset='ReferenceField')\n",
    "\n",
    "print(\"Total of distinct exported reference fields after de-duplication:\", df_multiple_invoice_dedup['ReferenceField'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.sort_values of        INVOICE_NBR  Count of Distinct ReferenceField\n",
      "71399   5107203768                                 2\n",
      "0       5105600111                                 1\n",
      "100142  5108637035                                 1\n",
      "100136  5108636743                                 1\n",
      "100137  5108636745                                 1\n",
      "...            ...                               ...\n",
      "50071   5106757048                                 1\n",
      "50072   5106757049                                 1\n",
      "50073   5106757050                                 1\n",
      "50074   5106757061                                 1\n",
      "150210  5109999553                                 1\n",
      "\n",
      "[150211 rows x 2 columns]>\n",
      "Count of INVOICE_NBR with one count of Distinct ReferenceField : 150210\n",
      "Count of INVOICE_NBR with more than one count of Distinct ReferenceField: 1\n"
     ]
    }
   ],
   "source": [
    "#2. There are Multiple 'ReferenceField' per 'INVOICE_NBR'\n",
    "inv_result = df.groupby('INVOICE_NBR')['ReferenceField'].nunique().reset_index()\n",
    "inv_result = inv_result.rename(columns={'ReferenceField': 'Count of Distinct ReferenceField'})\n",
    "inv_result = inv_result.sort_values(by='Count of Distinct ReferenceField', ascending=False)\n",
    "\n",
    "print(inv_result.sort_values)\n",
    "\n",
    "# Count of ReferenceField with one count of Distinct INVOICE_NBR\n",
    "one_count = inv_result[inv_result['Count of Distinct ReferenceField'] == 1]['INVOICE_NBR'].count()\n",
    "print(\"Count of INVOICE_NBR with one count of Distinct ReferenceField :\", one_count)\n",
    "\n",
    "# Count of ReferenceField with more than one count of Distinct INVOICE_NBR\n",
    "multiple_count = inv_result[inv_result['Count of Distinct ReferenceField'] > 1]['INVOICE_NBR'].count()\n",
    "print(\"Count of INVOICE_NBR with more than one count of Distinct ReferenceField:\", multiple_count)\n",
    "\n",
    "#inv_result.to_csv('Multiple_ReferenceField_per_INVOICE_NBR_.csv', encoding='UTF-8-SIG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LOGICSOUERCE02\\AppData\\Local\\Temp\\ipykernel_168\\215292781.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  update_data.drop_duplicates(subset='ReferenceField', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       INVOICE_NBR ReferenceField\n",
      "0       5109902481        2945886\n",
      "13      5109851350        QP801HN\n",
      "14      5109851364        QP800HN\n",
      "15      5109851365        QP815HN\n",
      "16      5109851366        QP810HN\n",
      "...            ...            ...\n",
      "323405  5107066802    093022-7088\n",
      "323407  5107305448      202204710\n",
      "323409  5107205343         323493\n",
      "323410  5107372171        000301C\n",
      "323411  5107242787           3360\n",
      "\n",
      "[144486 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#gnfr update table final check and export\n",
    "import numpy as np\n",
    "\n",
    "#table export nonpo Reference Field Update List \n",
    "\n",
    "#filtered DataFrame with rows where a single INVOICE_NBR has more than one distinct reference field\n",
    "update_data = df[df['ReferenceField'].isin(ref_result[ref_result['Count of Distinct INVOICE_NBR'] == 1]['ReferenceField'])]\n",
    "\n",
    "#remove duplicates in 'ReferenceField' column\n",
    "update_data.drop_duplicates(subset='ReferenceField', inplace=True)\n",
    "\n",
    "update_data = update_data[update_data['INVOICE_NBR'] != '5107203768']\n",
    " \n",
    "update_data = update_data[['INVOICE_NBR', 'ReferenceField']]\n",
    "\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(update_data)\n",
    "\n",
    "dtype = {\n",
    "    'INVOICE_NBR': 'str',\n",
    "    'ReferenceField': 'str',\n",
    "}\n",
    "\n",
    "update_data = update_data .astype(dtype)\n",
    "update_data .replace('', np.nan, inplace=True)\n",
    "update_data .to_csv('gnfr_invoice_update.csv', index=False, encoding='UTF-8-SIG')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #777777;\">2. NONPO Invoice</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #777777;\">2.1. Data Overview</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2679583, 17)\n",
      "                        Source.Name  Row_Count\n",
      "0   TBC_NONPO_01012022-01312022.CSV     104888\n",
      "1   TBC_NONPO_01012023-01312023.CSV      55799\n",
      "2   TBC_NONPO_02012022-02282022.CSV     102315\n",
      "3   TBC_NONPO_02012023-02282023.CSV      40367\n",
      "4   TBC_NONPO_03012022-03312022.CSV     136918\n",
      "5   TBC_NONPO_03012023-03312023.CSV      48604\n",
      "6   TBC_NONPO_05012021-05312021.CSV     143361\n",
      "7   TBC_NONPO_06012021-06302021.CSV     121229\n",
      "8   TBC_NONPO_06012022-06302022.CSV     134072\n",
      "9   TBC_NONPO_07012021-07312021.CSV     168277\n",
      "10  TBC_NONPO_07012022-07312022.CSV     119392\n",
      "11  TBC_NONPO_08012021-08312021.CSV     122428\n",
      "12  TBC_NONPO_08012022-08312022.CSV     115422\n",
      "13  TBC_NONPO_09012021-09302021.CSV     255268\n",
      "14  TBC_NONPO_09012022-09302022.CSV     134228\n",
      "15  TBC_NONPO_10012021-10312021.CSV     155738\n",
      "16  TBC_NONPO_10012022-10312022.CSV     121357\n",
      "17  TBC_NONPO_11012021-11302021.CSV     158050\n",
      "18  TBC_NONPO_11012022-11302022.CSV     125537\n",
      "19  TBC_NONPO_12012021-12312021.CSV     159966\n",
      "20  TBC_NONPO_12012022-12312022.CSV     156367\n"
     ]
    }
   ],
   "source": [
    "# Data shape and row count\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the data types for the columns\n",
    "dtype = {\n",
    "'Source.Name': 'str',\n",
    "'ACCOUNT_CDE': 'str',\n",
    "'INVOICE_NBR': 'str',\n",
    "'INVOICE_LINE_NBR': 'str',\n",
    "'SUPPLIER_NBR': 'str',\n",
    "}\n",
    "\n",
    "# Specify the directory where the csv files are\n",
    "directory_path = 'C:\\\\Users\\\\LOGICSOUERCE02\\\\Downloads\\\\TBC RELATED\\\\TBC Invoice Update\\\\1 - NONPO\\\\Monthly I2P Data\\\\TO CONCAT'\n",
    "\n",
    "# List to hold dataframes\n",
    "dfs = []\n",
    "\n",
    "# Iterate over the files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.csv'):  # Make sure we're working with CSV files\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(file_path, encoding='UTF-8-SIG', encoding_errors='ignore', dtype=dtype)\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all the dataframes into one\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(all_data.shape)\n",
    "\n",
    "df3 = all_data.groupby(['Source.Name']).size().reset_index(name='Row_Count')\n",
    "df3.to_csv('nonpo_row_count.csv', header=True, index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Source.Name  Row_Count\n",
      "0   TBC_NONPO_01012022-01312022.CSV     100787\n",
      "1   TBC_NONPO_01012023-01312023.CSV      55309\n",
      "2   TBC_NONPO_02012022-02282022.CSV      97400\n",
      "3   TBC_NONPO_02012023-02282023.CSV      39871\n",
      "4   TBC_NONPO_03012022-03312022.CSV     131456\n",
      "5   TBC_NONPO_03012023-03312023.CSV      47827\n",
      "6   TBC_NONPO_05012021-05312021.CSV     138719\n",
      "7   TBC_NONPO_06012021-06302021.CSV     115821\n",
      "8   TBC_NONPO_06012022-06302022.CSV     127503\n",
      "9   TBC_NONPO_07012021-07312021.CSV     160553\n",
      "10  TBC_NONPO_07012022-07312022.CSV     111132\n",
      "11  TBC_NONPO_08012021-08312021.CSV     116382\n",
      "12  TBC_NONPO_08012022-08312022.CSV     108649\n",
      "13  TBC_NONPO_09012021-09302021.CSV     250670\n",
      "14  TBC_NONPO_09012022-09302022.CSV     127045\n",
      "15  TBC_NONPO_10012021-10312021.CSV     148534\n",
      "16  TBC_NONPO_10012022-10312022.CSV     119957\n",
      "17  TBC_NONPO_11012021-11302021.CSV     152526\n",
      "18  TBC_NONPO_11012022-11302022.CSV     124107\n",
      "19  TBC_NONPO_12012021-12312021.CSV     153553\n",
      "20  TBC_NONPO_12012022-12312022.CSV     155519\n"
     ]
    }
   ],
   "source": [
    "# Row count after the filtering\n",
    "\n",
    "all_data['SUPPLIER_NBR'] = all_data['SUPPLIER_NBR'].astype(str)\n",
    "all_data['ACCOUNT_CDE'] = all_data['ACCOUNT_CDE'].astype(str)\n",
    "\n",
    "filtered_df = all_data[\n",
    "    ~(\n",
    "        (all_data['SUPPLIER_NBR'].str.startswith('E')) |\n",
    "        ((all_data['ACCOUNT_CDE'] == '121020') & (all_data['SUPPLIER_NBR'] == '176294'))\n",
    "    )\n",
    "]\n",
    "\n",
    "filtered_row_count = filtered_df.groupby(['Source.Name']).size().reset_index(name='Row_Count')\n",
    "filtered_row_count.to_csv('filtered_datase1.csv', header=True, index=False)\n",
    "\n",
    "\n",
    "print(filtered_row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sum of INVOICE_LINE_AMOUNT for each Source.Name:\n",
      "Source.Name\n",
      "TBC_NONPO_01012022-01312022.CSV    6.497143e+07\n",
      "TBC_NONPO_01012023-01312023.CSV    1.278833e+08\n",
      "TBC_NONPO_02012022-02282022.CSV    4.726563e+07\n",
      "TBC_NONPO_02012023-02282023.CSV    1.570666e+08\n",
      "TBC_NONPO_03012022-03312022.CSV    8.401463e+07\n",
      "TBC_NONPO_03012023-03312023.CSV    1.711548e+08\n",
      "TBC_NONPO_05012021-05312021.CSV    4.304693e+07\n",
      "TBC_NONPO_06012021-06302021.CSV    1.407635e+08\n",
      "TBC_NONPO_06012022-06302022.CSV    1.337452e+08\n",
      "TBC_NONPO_07012021-07312021.CSV    5.987502e+07\n",
      "TBC_NONPO_07012022-07312022.CSV    1.992246e+08\n",
      "TBC_NONPO_08012021-08312021.CSV    3.848289e+07\n",
      "TBC_NONPO_08012022-08312022.CSV    2.178124e+08\n",
      "TBC_NONPO_09012021-09302021.CSV    6.804769e+07\n",
      "TBC_NONPO_09012022-09302022.CSV    2.114267e+08\n",
      "TBC_NONPO_10012021-10312021.CSV    6.367520e+07\n",
      "TBC_NONPO_10012022-10312022.CSV    2.931100e+08\n",
      "TBC_NONPO_11012021-11302021.CSV    4.962345e+07\n",
      "TBC_NONPO_11012022-11302022.CSV    1.996113e+08\n",
      "TBC_NONPO_12012021-12312021.CSV    1.822740e+08\n",
      "TBC_NONPO_12012022-12312022.CSV    1.677856e+08\n",
      "Name: INVOICE_LINE_AMOUNT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate sum of INVOICE_LINE_AMOUNT for each Source.Name\n",
    "df3_amount_sum = all_data.groupby('Source.Name')['INVOICE_LINE_AMOUNT'].sum()\n",
    "\n",
    "df3_amount_sum.to_csv('database1_amount_sum.csv', header=True, encoding='UTF-8-SIG')\n",
    "\n",
    "print(\"\\nSum of INVOICE_LINE_AMOUNT for each Source.Name:\")\n",
    "print(df3_amount_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sum of INVOICE_LINE_AMOUNT for each Source.Name:\n",
      "Source.Name\n",
      "TBC_NONPO_01012022-01312022.CSV    6.449962e+07\n",
      "TBC_NONPO_01012023-01312023.CSV    1.277524e+08\n",
      "TBC_NONPO_02012022-02282022.CSV    4.672874e+07\n",
      "TBC_NONPO_02012023-02282023.CSV    1.568240e+08\n",
      "TBC_NONPO_03012022-03312022.CSV    8.341433e+07\n",
      "TBC_NONPO_03012023-03312023.CSV    1.709531e+08\n",
      "TBC_NONPO_05012021-05312021.CSV    4.248243e+07\n",
      "TBC_NONPO_06012021-06302021.CSV    1.401176e+08\n",
      "TBC_NONPO_06012022-06302022.CSV    1.331826e+08\n",
      "TBC_NONPO_07012021-07312021.CSV    5.900345e+07\n",
      "TBC_NONPO_07012022-07312022.CSV    1.984132e+08\n",
      "TBC_NONPO_08012021-08312021.CSV    3.779398e+07\n",
      "TBC_NONPO_08012022-08312022.CSV    2.170890e+08\n",
      "TBC_NONPO_09012021-09302021.CSV    6.751828e+07\n",
      "TBC_NONPO_09012022-09302022.CSV    2.106672e+08\n",
      "TBC_NONPO_10012021-10312021.CSV    6.300804e+07\n",
      "TBC_NONPO_10012022-10312022.CSV    2.926953e+08\n",
      "TBC_NONPO_11012021-11302021.CSV    4.907541e+07\n",
      "TBC_NONPO_11012022-11302022.CSV    1.988727e+08\n",
      "TBC_NONPO_12012021-12312021.CSV    1.816254e+08\n",
      "TBC_NONPO_12012022-12312022.CSV    1.675270e+08\n",
      "Name: INVOICE_LINE_AMOUNT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate filtered sum of INVOICE_LINE_AMOUNT for each Source.Name\n",
    "filtered_amount_sum = filtered_df.groupby('Source.Name')['INVOICE_LINE_AMOUNT'].sum()\n",
    "\n",
    "filtered_amount_sum.to_csv('filtered_database1_amount_sum.csv', header=True, encoding='UTF-8-SIG')\n",
    "\n",
    "print(\"\\nSum of INVOICE_LINE_AMOUNT for each Source.Name:\")\n",
    "print(filtered_amount_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5035947 entries, 0 to 5035946\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Source.Name        object \n",
      " 1   INVOICE_DATE       object \n",
      " 2   INVOICE_NBR        object \n",
      " 3   ReferenceField     object \n",
      " 4   INVOICE_PAID_DATE  object \n",
      " 5   INVOICE_LINE_NBR   float64\n",
      " 6   INVOICE_QTY        float64\n",
      " 7   INVOICE_SOURCE     object \n",
      " 8   INVOICE_TYPE       object \n",
      " 9   PO_NBR             object \n",
      " 10  PO_ORDER_DATE      float64\n",
      " 11  SUPPLIER_NBR       object \n",
      "dtypes: float64(3), object(9)\n",
      "memory usage: 461.1+ MB\n"
     ]
    }
   ],
   "source": [
    "all_data.info(verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #777777;\">2.2. Transformation / Reports</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

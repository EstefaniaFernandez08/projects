{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "# File paths\n",
    "source_file_path = '2023 Vendor Power Pivot FAF_12.14.23.xlsx'\n",
    "export_file_path = 'Invoice_FAF_OCT 12.14.23.csv'\n",
    "\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(source_file_path, sheet_name='Pasted Values 12.14.23')\n",
    "\n",
    "# Add Year and AA_YEAR columns with default or calculated values\n",
    "# TODO: Implement the logic for populating 'Year' and 'AA_YEAR' if they are derived from other data\n",
    "df['Delivery Date'] = '12.14.23'\n",
    "df['Year'] = '2023'  # Replace with the necessary logic\n",
    "df['AA_YEAR'] = ''  # Replace with the necessary logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate file names based on period and year\n",
    "def generate_file_name(period, year):\n",
    "    month_number = int(period.split(' ')[1])\n",
    "    start_date = datetime(year, month_number, 1)\n",
    "    \n",
    "    # Get the last day of the month\n",
    "    last_day = calendar.monthrange(year, month_number)[1]\n",
    "    end_date = datetime(year, month_number, last_day)\n",
    "    \n",
    "    return f'SUB_INV_FAF_{start_date.strftime(\"%m%d%Y\")}-{end_date.strftime(\"%m%d%Y\")}'\n",
    "\n",
    "def generate_unique_id(df):\n",
    "    # Concatenate 'Vendor ID' and 'Invoice #' to form a unique key\n",
    "    df['unique_key'] = df['Vendor ID'] + df['Invoice #'] + df['Corporate Net Amount'].astype(str)\n",
    "    \n",
    "    # Sort by 'unique_key' to ensure the order is consistent\n",
    "    df = df.sort_values(by='unique_key')\n",
    "    \n",
    "    # Create a group identifier that increments for each unique 'unique_key'\n",
    "    df['group_id'] = df.groupby('unique_key').cumcount() + 1\n",
    "    \n",
    "    # Create the 'ASSETID' by concatenating the 'group_id' and 'unique_key'\n",
    "    df['ASSETID'] = df['group_id'].astype(str) + '-' + df['unique_key']\n",
    "    \n",
    "    # Drop the helper columns 'unique_key' and 'group_id'\n",
    "    df = df.drop(columns=['unique_key', 'group_id'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Mapping periods to the Month column and filtering rows\n",
    "def update_period_data(df, periods):\n",
    "    quarter_map = {\n",
    "        'Period 1': 'Quarter 1', 'Period 2': 'Quarter 1', 'Period 3': 'Quarter 1',\n",
    "        'Period 4': 'Quarter 2', 'Period 5': 'Quarter 2', 'Period 6': 'Quarter 2',\n",
    "        'Period 7': 'Quarter 3', 'Period 8': 'Quarter 3', 'Period 9': 'Quarter 3',\n",
    "        'Period 10': 'Quarter 4', 'Period 11': 'Quarter 4', 'Period 12': 'Quarter 4'\n",
    "    }\n",
    "    # Update Month, Quarter, Corporate Net Amount\n",
    "    for period in periods:\n",
    "        df.loc[df[period].notna(), 'Month'] = period\n",
    "        df.loc[df[period].notna(), 'Quarter'] = quarter_map[period]\n",
    "        df.loc[df[period].notna(), 'Corporate Net Amount'] = df[period]\n",
    "\n",
    "\n",
    "    # Generate the 'FILE_NAME' column\n",
    "    for period in periods:\n",
    "        year_column = df['Year'].astype(int)  # Convert 'Year' column to integer\n",
    "        mask = (df['Month'] == period) & (year_column > 0)  # Create a mask for rows corresponding to the period\n",
    "        file_names = year_column[mask].apply(lambda y: generate_file_name(period, y))  # Generate file names\n",
    "        df.loc[mask, 'FILE_NAME'] = file_names  # Assign generated file names to 'FILE_NAME' column\n",
    "        \n",
    "    # Inside update_period_data function, after updating 'Corporate Net Amount'\n",
    "    df['Corporate Net Amount'] = df['Corporate Net Amount'].astype(float)\n",
    "    \n",
    "    # Capture the Grand Total value and exclude it\n",
    "    grand_total  = df.loc[df['Subway or FAF'] == 'Grand Total', 'Corporate Net Amount'].iloc[0]\n",
    "    df = df[df['Subway or FAF'] != 'Grand Total'] \n",
    "\n",
    "    # Create a mask for rows related to specified periods\n",
    "    mask = df[periods].notna().any(axis=1)\n",
    "    df = df[mask]\n",
    "    \n",
    "    # Call generate_unique_id to add the 'ASSETID' column\n",
    "    df = generate_unique_id(df)\n",
    "\n",
    "    return df, grand_total\n",
    "\n",
    "# Specify the periods you're interested in\n",
    "period_cols = ['Period 10'] # Add other periods as needed\n",
    "\n",
    "# Call update_period_data and receive the grand total\n",
    "df, grand_total = update_period_data(df, period_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output columns and include 'FILE_NAME'\n",
    "output_columns = [\n",
    "    'Subway or FAF', 'Year', 'Quarter', 'Month', 'GL Category', 'FPA Function', \n",
    "    'Project Code', 'Project Code Description', 'GL Description', 'Vendor ID', \n",
    "    'Vendor Name', 'Invoice #', 'Corporate Net Amount', 'Vendor', \n",
    "    'Org Unit - Description', 'ORG UNIT _ Business Unit Rollup', \n",
    "    'ORG UNIT _ Region Rollup', 'AA_YEAR', 'CorpSegment6 _ FAF Working Capital', \n",
    "    'Doc Date', 'CorpSegment6 _ Consolidated Mapping _ Description', \n",
    "    'CorpSegment6 _ FAF Category', 'CorpSegment6 _ FAF Category _ Description', \n",
    "    'CorpSegment6 _ FAF Managerial Mapping', 'CorpSegment6 _ FAF Managerial Mapping Description', \n",
    "    'CorpSegment6 _ Unconsolidated Mapping', 'CorpSegment6 _ Unconsolidated Mapping Description'\n",
    "]  + ['FILE_NAME', 'ASSETID', 'Delivery Date']\n",
    "\n",
    "# Ensure all desired columns are in the DataFrame, filling missing ones with blanks\n",
    "for col in output_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = ''\n",
    "\n",
    "# Reorder and select columns as per requirement\n",
    "df_final = df[output_columns]\n",
    "\n",
    "# Export to CSV with UTF-8-SIG encoding\n",
    "df_final.to_csv(export_file_path, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the filtering is accurate before exporting the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated total matches the Grand Total (53557154.22).\n",
      "Row count for Period 10: 1443\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ensure both values are floats for comparison\n",
    "calculated_total = float(df['Corporate Net Amount'].sum())\n",
    "grand_total = float(grand_total)\n",
    "\n",
    "# Total amount check before exporting\n",
    "calculated_total = df['Corporate Net Amount'].sum()\n",
    "if not np.isclose(calculated_total, grand_total):\n",
    "    print(f\"Warning: The calculated total ({calculated_total}) does not match the Grand Total ({grand_total}).\")\n",
    "else:\n",
    "    print(f\"The calculated total matches the Grand Total ({calculated_total}).\")\n",
    "    \n",
    "# Print the row count for each selected period\n",
    "for period in period_cols:\n",
    "    period_count = df[df['Month'] == period].shape[0]\n",
    "    print(f\"Row count for {period}: {period_count}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

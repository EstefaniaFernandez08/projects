{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\diana.fernandez\\AppData\\Local\\Temp\\1\\ipykernel_4160\\1435315965.py:53: DtypeWarning: Columns (7,32,57,59,62,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv('TBC_OUTPUT_SAP_FY23_DEC-JAN v.2.csv', encoding='UTF-8-SIG', encoding_errors='ignore', dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame1 shape: (8386, 90)\n",
      "DataFrame2 shape: (64469, 90)\n",
      "Non-null values in  df1: 8220\n",
      "Non-null values in df2: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "dtype = {\n",
    "    'ACCOUNT_CDE': 'str',  \n",
    "    'ASSETID':'str',\n",
    "    'BUSINESS_UNIT':'str',\n",
    "    'BUSINESS_UNIT_CDE': 'str', \n",
    "    'BUYER_ID': 'str', \n",
    "    'COMPANY_CDE': 'str',\n",
    "    'COST_CENTER': 'str', \n",
    "    'COST_CENTER_DESC': 'str',\n",
    "    'EXPENSE_REPORT_NAME': 'str',\n",
    "    'FILE_NAME': 'str',\n",
    "    'FISCAL_MONTH': 'str',\n",
    "    'FISCAL_QUARTER': 'str',\n",
    "    'FISCAL_YEAR': 'str',\n",
    "    'INVOICE_COMMENT': 'str',\n",
    "    'INVOICE_PMT_TERMS': 'str',\n",
    "    'INVOICE_LINE_DESC': 'str',\n",
    "    'INVOICE_LINE_NBR': 'str', \n",
    "    'INVOICE_LINE_QTY': 'str', \n",
    "    'INVOICE_LINE_UNIT_PRICE': 'str', \n",
    "    'INVOICE_NBR': 'str', \n",
    "    'INVOICE_PMT_TERMS_CDE': 'str', \n",
    "    'LEGAL_ENTITY_CDE': 'str',\n",
    "    'LOCATION': 'str', \n",
    "    'LOCATION_ID': 'str',\n",
    "    'PAYMENT_TYPE': 'str',\n",
    "    'PO_LINE_DESC': 'str',\n",
    "    'PO_LINE_ITEM_ID': 'str', \n",
    "    'PO_LINE_NBR': 'str', \n",
    "    'PO_LINE_QTY': 'str', \n",
    "    'PO_NBR': 'str', \n",
    "    'PROJECT_NAME':'str',\n",
    "    'PROJECT_DESCRIPTION': 'str',\n",
    "    'SUPPLIER_ADDRESS_1': 'str',\n",
    "    'SUPPLIER_GRP': 'str',\n",
    "    'SUPPLIER_ERP': 'str',\n",
    "    'SUPPLIER_NBR': 'str',\n",
    "    'SUPPLIER_NORMALIZED': 'str',\n",
    "    'SUPPLIER_PMT_TERM_CDE': 'str',\n",
    "    'SUPPLIER_STATE': 'str',\n",
    "    'SUPPLIER_TAXID': 'str',\n",
    "    'SUPPLIER_ZIP_POSTAL_CDE':'str',\n",
    "    'DAYS_ATF_PO': 'str', \n",
    "    'INVOICE_LINE_AMOUNT': 'float',\n",
    "    'EXCHANGE_RATE': 'float',\n",
    "    'TOTAL_SPEND_USD': 'float',\n",
    "    'TOTAL_SPEND':'float',\n",
    "}\n",
    "\n",
    "df1 = pd.read_csv('ATF2_TBC_OUTPUT_CONCUR_FY23 Q3_OCT v.2.csv', encoding='UTF-8-SIG', encoding_errors='ignore', dtype=dtype)\n",
    "df2 = pd.read_csv('ATF3_TBC_OUTPUT_CONCUR_FY23 Q3_OCT v.2.csv', encoding='UTF-8-SIG', encoding_errors='ignore', dtype=dtype)\n",
    "\n",
    "df1_shape = df1.shape\n",
    "print(\"DataFrame1 shape:\", df1_shape)\n",
    "\n",
    "df2_shape = df2.shape\n",
    "print(\"DataFrame2 shape:\", df2_shape)\n",
    "\n",
    "# Count of non-null values in 'SUPPLIER_NORMALIZED' in df1\n",
    "nonnull_count_df1 = df1['SUPPLIER_NORMALIZED'].notna().sum()\n",
    "\n",
    "# Count of non-null values in 'SUPPLIER_NORMALIZED' in df2\n",
    "nonnull_count_df2 = df2['SUPPLIER_NORMALIZED'].notna().sum()\n",
    "\n",
    "print(f\"Non-null values in  df1: {nonnull_count_df1}\")\n",
    "print(f\"Non-null values in df2: {nonnull_count_df2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the merged DataFrame: (4981, 90)\n",
      "Non-null values in 'SUPPLIER_NORMALIZED': 1533\n"
     ]
    }
   ],
   "source": [
    "# Define the columns on which you want to merge\n",
    "merge_keys = ['ASSETID', 'FILE_NAME']\n",
    "\n",
    "# Perform the full outer join on the specified keys\n",
    "merged_df = pd.merge(df1, df2, on=merge_keys, how='outer', suffixes=('', '_df2'))\n",
    "\n",
    "# Now, we need to address the 'SUPPLIER_NORMALIZED' column specifically\n",
    "# We fill NaNs in 'SUPPLIER_NORMALIZED' from df1 with values from df2\n",
    "merged_df['SUPPLIER_NORMALIZED'] = merged_df['SUPPLIER_NORMALIZED'].combine_first(merged_df['SUPPLIER_NORMALIZED_df2'])\n",
    "\n",
    "# For all other columns, we want to keep the original values from df1\n",
    "# So we drop the duplicate columns from df2\n",
    "columns_to_drop = [col for col in merged_df if col.endswith('_df2') and col != 'SUPPLIER_NORMALIZED_df2']\n",
    "merged_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# We also drop the suffixed 'SUPPLIER_NORMALIZED' column from df2\n",
    "merged_df.drop(columns=['SUPPLIER_NORMALIZED_df2'], inplace=True)\n",
    "\n",
    "# Verify the shape of the DataFrame\n",
    "assert merged_df.shape == (4981, 90), f\"Unexpected DataFrame shape: {merged_df.shape}\"\n",
    "\n",
    "# Verify the number of non-null values in 'SUPPLIER_NORMALIZED'\n",
    "nonnull_count = merged_df['SUPPLIER_NORMALIZED'].notna().sum()\n",
    "print(f\"Shape of the merged DataFrame: {merged_df.shape}\")\n",
    "print(f\"Non-null values in 'SUPPLIER_NORMALIZED': {nonnull_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('ATF3_TBC_OUTPUT_CONCUR_FY23 Q3_OCT v.2.csv', encoding='UTF-8-SIG', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
